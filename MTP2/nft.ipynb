{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching assets: 403\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39m# Add a delay between requests to avoid hitting rate limits\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)  \u001b[39m# Adjust the delay (in seconds) as needed\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(dataframes)\n\u001b[0;32m     74\u001b[0m combined_df\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcategory\u001b[39m}\u001b[39;00m\u001b[39m_nfts.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[39m=\u001b[39mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[39m=\u001b[39mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[39m=\u001b[39mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    426\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    428\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_opensea_assets(offset, category):\n",
    "    url = \"https://api.opensea.io/api/v1/assets\"\n",
    "    query = {\n",
    "        \"offset\": offset,\n",
    "        \"limit\": 50,\n",
    "        \"asset_category\": category,\n",
    "    }\n",
    "\n",
    "    headers = {\"X-API-KEY\": \"your_api_key_here\"}\n",
    "\n",
    "    response = requests.get(url, params=query, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching assets: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def fetch_opensea_events(token_id, asset_contract_address):\n",
    "    url = \"https://api.opensea.io/api/v1/events\"\n",
    "    query = {\n",
    "        \"asset_contract_address\": asset_contract_address,\n",
    "        \"token_id\": token_id,\n",
    "        \"event_type\": \"successful\",\n",
    "        \"limit\": 50,\n",
    "    }\n",
    "    response = requests.get(url, params=query)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching events: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def process_opensea_data(data):\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    assets = []\n",
    "    for asset in data['assets']:\n",
    "        try:\n",
    "            events = fetch_opensea_events(asset['token_id'], asset['asset_contract']['address'])\n",
    "            latest_sale = events['asset_events'][0] if events and events['asset_events'] else None\n",
    "\n",
    "            assets.append({\n",
    "                # ... (same as before)\n",
    "            })\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(assets)\n",
    "\n",
    "categories = ['gaming', 'music', 'art']\n",
    "\n",
    "for category in categories:\n",
    "    offset = 0\n",
    "    dataframes = []\n",
    "\n",
    "    while True:\n",
    "        data = fetch_opensea_assets(offset, category)\n",
    "        if not data or not data['assets']:\n",
    "            break\n",
    "\n",
    "        df = process_opensea_data(data)\n",
    "        dataframes.append(df)\n",
    "\n",
    "        offset += 50\n",
    "\n",
    "        # Add a delay between requests to avoid hitting rate limits\n",
    "        time.sleep(5)  # Adjust the delay (in seconds) as needed\n",
    "\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    combined_df.to_csv(f\"{category}_nfts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.rarible.com', port=443): Max retries exceeded with url: /protocol/v0.1/ethereum/nft/items?offset=0&limit=50&categories=gaming (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000196E23DBC10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    961\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 962\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39m, proto, flags):\n\u001b[0;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_conn()\n\u001b[0;32m    364\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000196E23DBC10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39me, _pool\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, _stacktrace\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.rarible.com', port=443): Max retries exceeded with url: /protocol/v0.1/ethereum/nft/items?offset=0&limit=50&categories=gaming (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000196E23DBC10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m dataframes \u001b[39m=\u001b[39m []\n\u001b[0;32m     80\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     data \u001b[39m=\u001b[39m fetch_rarible_items(offset, category)\n\u001b[0;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m data[\u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     83\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 12\u001b[0m, in \u001b[0;36mfetch_rarible_items\u001b[1;34m(offset, category)\u001b[0m\n\u001b[0;32m      6\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://api.rarible.com/protocol/v0.1/ethereum/nft/items\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m query \u001b[39m=\u001b[39m {\n\u001b[0;32m      8\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moffset\u001b[39m\u001b[39m\"\u001b[39m: offset,\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlimit\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m50\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcategories\u001b[39m\u001b[39m\"\u001b[39m: category,\n\u001b[0;32m     11\u001b[0m }\n\u001b[1;32m---> 12\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, params\u001b[39m=\u001b[39mquery)\n\u001b[0;32m     14\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError fetching items: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Pradhumnya\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.rarible.com', port=443): Max retries exceeded with url: /protocol/v0.1/ethereum/nft/items?offset=0&limit=50&categories=gaming (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000196E23DBC10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def fetch_rarible_items(offset, category):\n",
    "    url = \"https://api.rarible.com/protocol/v0.1/ethereum/nft/items\"\n",
    "    query = {\n",
    "        \"offset\": offset,\n",
    "        \"limit\": 50,\n",
    "        \"categories\": category,\n",
    "    }\n",
    "    response = requests.get(url, params=query)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching items: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def fetch_rarible_orders(item_id):\n",
    "    url = f\"https://api.rarible.com/protocol/v0.1/ethereum/order/orders\"\n",
    "    query = {\n",
    "        \"itemId\": item_id,\n",
    "    }\n",
    "    response = requests.get(url, params=query)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error fetching orders: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def process_rarible_data(data):\n",
    "    if not data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    items = []\n",
    "    for item in data['items']:\n",
    "        try:\n",
    "            item_id = item['id']\n",
    "            orders = fetch_rarible_orders(item_id)\n",
    "\n",
    "            sale_orders = [o for o in orders['orders'] if o['type'] == 'SELL']\n",
    "            bid_orders = [o for o in orders['orders'] if o['type'] == 'BID']\n",
    "\n",
    "            latest_sale_order = sale_orders[0] if sale_orders else None\n",
    "            latest_bid_order = bid_orders[0] if bid_orders else None\n",
    "\n",
    "            items.append({\n",
    "                \"NFT ID\": item_id,\n",
    "                \"Name\": item['meta']['name'],\n",
    "                \"Description\": item['meta']['description'],\n",
    "                \"Image\": item['meta']['image']['url'],\n",
    "                \"Collection\": item['collection']['name'],\n",
    "                \"Category\": ','.join(item['categories']),\n",
    "                \"Creator\": item['mintedBy'],\n",
    "                \"Owner\": item['owners'][0],\n",
    "                \"Sale Date\": latest_sale_order['createdAt'] if latest_sale_order else None,\n",
    "                \"Sale Price\": latest_sale_order['make']['value'] if latest_sale_order else None,\n",
    "                \"Sale Currency\": latest_sale_order['make']['assetType']['symbol'] if latest_sale_order else None,\n",
    "                \"Buyer\": latest_sale_order['taker'] if latest_sale_order else None,\n",
    "                \"Seller\": latest_sale_order['maker'] if latest_sale_order else None,\n",
    "                \"Bid Date\": latest_bid_order['createdAt'] if latest_bid_order else None,\n",
    "                \"Bid Price\": latest_bid_order['take']['value'] if latest_bid_order else None,\n",
    "                \"Bid Currency\": latest_bid_order['take']['assetType']['symbol'] if latest_bid_order else None,\n",
    "                \"Bidder\": latest_bid_order['maker'] if latest_bid_order else None,\n",
    "            })\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(items)\n",
    "\n",
    "\n",
    "categories = ['gaming', 'music', 'art']\n",
    "\n",
    "for category in categories:\n",
    "    offset = 0\n",
    "    dataframes = []\n",
    "\n",
    "    while True:\n",
    "        data = fetch_rarible_items(offset, category)\n",
    "        if not data or not data['items']:\n",
    "            break\n",
    "\n",
    "        df = process_rarible_data(data)\n",
    "        dataframes.append(df)\n",
    "\n",
    "        offset += 50\n",
    "\n",
    "        # Add a delay between requests to avoid hitting rate limits\n",
    "        time.sleep(1)  # Adjust the delay (in seconds) as needed\n",
    "\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    combined_df.to_csv(f\"{category}_nfts_rarible_price_discovery.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
